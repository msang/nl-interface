{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5768d93-cd20-4d29-ad8e-08f9fcd64236",
   "metadata": {},
   "source": [
    "# Computing Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72ce2a-a564-4f1d-9478-5919c7387e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install krippendorff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac72904-6b11-41d4-bc45-2d4da645c037",
   "metadata": {},
   "source": [
    "Import all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610d3a0-d891-490f-9067-648882c1c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excl = ['id','intent','text','prompts','output']\n",
    "\n",
    "crb_df = pd.read_csv(\"EnergyFeedbackGeneration-EvaluationResults-Cerbero-7B.tsv\", sep=\"\\t\").drop(excl, axis=1)\n",
    "l2_df = pd.read_csv(\"EnergyFeedbackGeneration-EvaluationResults-LLaMAntino2.tsv\", sep=\"\\t\").drop(excl, axis=1)\n",
    "l3_df = pd.read_csv(\"EnergyFeedbackGeneration-EvaluationResults-LLaMAntino3.tsv\", sep=\"\\t\").drop(excl, axis=1)\n",
    "zef_df = pd.read_csv(\"EnergyFeedbackGeneration-EvaluationResults-Zefiro.tsv\", sep=\"\\t\").drop(excl, axis=1)\n",
    "#l2_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b25a79-4dda-40a2-b039-9ccce5c4eed4",
   "metadata": {},
   "source": [
    "## Inter-Annotator Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3fb7c9-6f4e-4658-8d7b-6e11339b3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "\n",
    "criteria = ['Usefulness', 'Necessity', 'Understandability', 'Fluency', 'Accuracy']\n",
    "model_names=['Cerbero', 'LLaMAntino2', 'LLaMAntino3', 'Zefiro']\n",
    "model_dfs = [crb_df, l2_df, l3_df, zef_df]\n",
    "\n",
    "def compute_alpha(df, criteria):\n",
    "\n",
    "    iaa = {}\n",
    "\n",
    "    for criterion in criteria:\n",
    "        columns = [col for col in df.columns if col.startswith(criterion)]\n",
    "        data = df[columns].values.T\n",
    "        #print(data)\n",
    "        alpha = krippendorff.alpha(reliability_data=data)\n",
    "        iaa[criterion] = alpha\n",
    "        print(f\"Krippendorff's alpha for {criterion}: {alpha:.2f}\")\n",
    "\n",
    "    return iaa\n",
    "\n",
    "\n",
    "def compute_average_alpha(criteria, model_iaas):\n",
    "    average_iaa = {}\n",
    "    for criterion in criteria:\n",
    "        alphas = [model_iaa[criterion] for model_iaa in model_iaas]\n",
    "        average_alpha = sum(alphas) / len(alphas)\n",
    "        average_iaa[criterion] = average_alpha\n",
    "        print(f\"Average alpha for {criterion}: {average_alpha:.2f}\")\n",
    "    return average_iaa\n",
    "\n",
    "# collect IAAs for each model\n",
    "model_iaas = []\n",
    "for model_name, df in zip(model_names, model_dfs):\n",
    "    print(model_name)\n",
    "    iaa = compute_alpha(df, criteria)\n",
    "    model_iaas.append(iaa)\n",
    "\n",
    "average_iaa = compute_average_alpha(criteria, model_iaas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51d3b4-4532-4a78-a349-b9d6bff0b6f1",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03438042-471f-4fff-bce7-7f2c4f4a1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384d61d-834c-4fe5-acd6-81f53d7b40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# conflate annotations keeping track of annotators\n",
    "def conflate_annotations(df, criteria):\n",
    "    conflated_df = pd.DataFrame()\n",
    "    for criterion in criteria:\n",
    "        criterion_scores = []\n",
    "        annotators = []\n",
    "        for i in range(4):\n",
    "            column = f\"{criterion}_A{i+1}\"\n",
    "            scores = df[column].values\n",
    "            criterion_scores.extend(scores)\n",
    "            annotator_info = [f\"A{i+1}\"] * len(scores)\n",
    "            annotators.extend(annotator_info)\n",
    "        conflated_df[criterion] = criterion_scores\n",
    "        conflated_df[f\"{criterion}_Annotator\"] = annotators\n",
    "    return conflated_df\n",
    "\n",
    "conflated_dfs = [conflate_annotations(df, criteria) for df in model_dfs]\n",
    "\n",
    "# combine all models into a single dataframe for each criterion\n",
    "data = []\n",
    "for model_name, conflated_df in zip(model_names, conflated_dfs):\n",
    "    for criterion in criteria:\n",
    "        for idx, score in enumerate(conflated_df[criterion].values):\n",
    "            annotator = conflated_df[f\"{criterion}_Annotator\"].values[idx]\n",
    "            data.append({'Model': model_name, 'Criterion': criterion, 'Score': score, 'Annotator': annotator})\n",
    "\n",
    "# df with ratings for each criterion and model\n",
    "df = pd.DataFrame(data)\n",
    "#print(df.head(10))\n",
    "\n",
    "\n",
    "# perform Kruskal-Wallis test + Dunn's test for each criterion \n",
    "eta_squared_results = {}\n",
    "for criterion in df['Criterion'].unique():\n",
    "    \n",
    "    print(criterion)\n",
    "    df_criterion = df[df['Criterion'] == criterion]\n",
    "    \n",
    "    # remove NaN values, if present\n",
    "    groups = [df_criterion[df_criterion['Model'] == model]['Score'].dropna().values for model in df_criterion['Model'].unique()]\n",
    "    \n",
    "    #print(f\"Groups for {criterion}:\")\n",
    "    #for i, group in enumerate(groups):\n",
    "        #print(f\"Group {i+1}: {group}\")\n",
    "\n",
    "    kruskal_test = kruskal(*groups)\n",
    "    print(kruskal_test)\n",
    "    \n",
    "    # Dunn's test with Bonferroni correction\n",
    "    dunn_results = sp.posthoc_dunn(df_criterion, val_col='Score', group_col='Model', p_adjust='bonferroni')\n",
    "    print(dunn_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8384c1-9f6b-4acb-b8a9-2ca94f505e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
